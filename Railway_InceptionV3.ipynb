{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiOOs46eiEEc",
        "outputId": "11a67e2b-7b68-4011-879c-78bebfceb6b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.15\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15)\n",
            "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.64.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.2.2)\n",
            "Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.66 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b roshan_b https://github.com/roshant2003/Railway-Track-Fault-Detection-Project\n",
        "!cp -r Railway-Track-Fault-Detection-Project/Railway/ /content/Dataset\n",
        "!cp -r Railway-Track-Fault-Detection-Project/Railway_pre/ /content/Dataset_Pre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UttvYPEYlqd9",
        "outputId": "b38932aa-86f0-4249-f22c-33b463399fcb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Railway-Track-Fault-Detection-Project'...\n",
            "remote: Enumerating objects: 10334, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 10334 (delta 1), reused 11 (delta 1), pack-reused 10322 (from 1)\u001b[K\n",
            "Receiving objects: 100% (10334/10334), 599.19 MiB | 22.76 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (10309/10309), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_pUZG7ChnBh",
        "outputId": "13d42f65-69b8-47c9-c30a-a494c6284e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4125 images belonging to 7 classes.\n",
            "Found 1028 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "data_dir = 'Dataset_Pre'\n",
        "\n",
        "n_classes = 7\n",
        "\n",
        "# Image parameters\n",
        "image_size = 224\n",
        "\n",
        "# Training parameters\n",
        "loss_metrics = ['accuracy']\n",
        "n_epochs = 100\n",
        "early_stop_patience = 10\n",
        "\n",
        "steps_per_epoch_training = 10\n",
        "steps_per_epoch_validation = 10\n",
        "\n",
        "batch_size_training = 20\n",
        "batch_size_validation = 20\n",
        "\n",
        "# Define ImageDataGenerator with augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "        zoom_range=0.15,\n",
        "        shear_range=0.15,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2,\n",
        "        rescale=1.0/255)\n",
        "\n",
        "# Training and validation generators\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size_training,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size_validation,\n",
        "        class_mode='categorical',\n",
        "        subset='validation')\n",
        "\n",
        "# Load the InceptionV3 model without the top layers (for transfer learning)\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "# Add new layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Global average pooling\n",
        "\n",
        "# Add fully connected layer with BatchNormalization and Dropout\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = BatchNormalization()(x)  # Batch Normalization\n",
        "x = Dropout(0.5)(x)  # Dropout for regularization\n",
        "\n",
        "# Add another Dense layer for the classification with softmax activation\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "# Define the full model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Fine-tune: Unfreeze the top layers of the InceptionV3 model\n",
        "for layer in base_model.layers[:249]:\n",
        "    layer.trainable = False  # Freeze layers\n",
        "for layer in base_model.layers[249:]:\n",
        "    layer.trainable = True   # Unfreeze the last layers for fine-tuning\n",
        "\n",
        "# Compile the model with a lower learning rate for fine-tuning\n",
        "optimizer = Adam(learning_rate=1e-4)  # Fine-tuning usually requires a lower learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=loss_metrics)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Compile model\n",
        "sgd = optimizers.SGD(learning_rate=0.01, weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=sgd, loss=objective_function, metrics=loss_metrics)\n",
        "\n"
      ],
      "metadata": {
        "id": "Z9n_KxUnh4FV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Ensure that the working directory exists\n",
        "if not os.path.exists('../working/'):\n",
        "    os.makedirs('../working/')\n",
        "\n",
        "# Prepare early stopping to avoid overfitting\n",
        "cb_early_stopper = EarlyStopping(monitor='val_loss', patience=early_stop_patience)\n",
        "cb_checkpointer = ModelCheckpoint(filepath='../working/best', monitor='val_loss', save_best_only=True, mode='auto')\n",
        "\n",
        "# Fit the model\n",
        "fit_history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch_training,\n",
        "        epochs=n_epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=steps_per_epoch_validation,\n",
        "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
        ")\n",
        "\n",
        "# Ensure the model checkpoint file exists before loading\n",
        "if os.path.exists(\"../working/best\"):\n",
        "    model.load_weights(\"../working/best\")\n",
        "else:\n",
        "    print(\"Checkpoint file not found!\")\n",
        "\n",
        "# Save the model to a valid path\n",
        "model.save(\"InceptionV3_RTFD.keras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqgu3WbCh8Yj",
        "outputId": "d90ef56a-49ca-4242-e1a6-db815d8e384c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 42s 4s/step - loss: 2.1151 - accuracy: 0.4950 - val_loss: 19.8480 - val_accuracy: 0.3550\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 1.5744 - accuracy: 0.7300 - val_loss: 69.8477 - val_accuracy: 0.3550\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 8s 821ms/step - loss: 0.6749 - accuracy: 0.8757 - val_loss: 23.9181 - val_accuracy: 0.1450\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 6s 608ms/step - loss: 0.8970 - accuracy: 0.8150 - val_loss: 25.9686 - val_accuracy: 0.1700\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 6s 605ms/step - loss: 0.6181 - accuracy: 0.8750 - val_loss: 62.9572 - val_accuracy: 0.3650\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 32s 4s/step - loss: 0.3423 - accuracy: 0.9250 - val_loss: 13.1972 - val_accuracy: 0.4050\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 6s 677ms/step - loss: 0.5714 - accuracy: 0.8850 - val_loss: 28.0849 - val_accuracy: 0.3350\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 8s 875ms/step - loss: 0.6506 - accuracy: 0.8650 - val_loss: 15.1500 - val_accuracy: 0.4450\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 35s 4s/step - loss: 0.2801 - accuracy: 0.9300 - val_loss: 6.6833 - val_accuracy: 0.4900\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 33s 4s/step - loss: 0.5154 - accuracy: 0.8950 - val_loss: 3.6208 - val_accuracy: 0.7300\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 35s 4s/step - loss: 0.4928 - accuracy: 0.9150 - val_loss: 0.6499 - val_accuracy: 0.8750\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.6175 - accuracy: 0.8850 - val_loss: 2.5872 - val_accuracy: 0.7850\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 8s 831ms/step - loss: 0.2837 - accuracy: 0.9300 - val_loss: 2.2088 - val_accuracy: 0.8000\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 8s 829ms/step - loss: 0.1965 - accuracy: 0.9400 - val_loss: 2.0028 - val_accuracy: 0.7850\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 6s 601ms/step - loss: 0.2932 - accuracy: 0.9250 - val_loss: 0.9643 - val_accuracy: 0.8500\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 8s 853ms/step - loss: 0.1524 - accuracy: 0.9700 - val_loss: 0.9086 - val_accuracy: 0.8950\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 8s 832ms/step - loss: 0.1495 - accuracy: 0.9700 - val_loss: 0.8409 - val_accuracy: 0.8750\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 8s 833ms/step - loss: 0.1611 - accuracy: 0.9550 - val_loss: 0.7404 - val_accuracy: 0.8650\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 8s 827ms/step - loss: 0.2228 - accuracy: 0.9500 - val_loss: 0.9413 - val_accuracy: 0.8450\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 8s 858ms/step - loss: 0.2644 - accuracy: 0.9350 - val_loss: 0.8891 - val_accuracy: 0.8300\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 8s 825ms/step - loss: 0.2377 - accuracy: 0.9650 - val_loss: 0.9935 - val_accuracy: 0.8500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TF Keras model\n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model(\"InceptionV3_RTFD.keras\")\n",
        "\n",
        "# Accuracy test with complete dataset\n",
        "import os\n",
        "import cv2\n",
        "import progressbar\n",
        "import numpy as np\n",
        "\n",
        "def classify(image):\n",
        "    # Pre-processing\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = np.array(np.expand_dims(image, 0), dtype=np.float32)\n",
        "    image = image / 255.\n",
        "    output = model.predict(image, verbose=0)\n",
        "    return np.argmax(output, axis=1)[0]\n",
        "\n",
        "def test_model(folder, classes, length):\n",
        "    class_idx = 0\n",
        "    curr_count = 0\n",
        "    correct_count = 0\n",
        "    with progressbar.ProgressBar(max_value=length) as bar:\n",
        "        for c in classes:\n",
        "            for f in os.listdir(os.path.join(folder, c)):\n",
        "                bar.update(curr_count)\n",
        "                image = cv2.imread(os.path.join(folder, c, f))\n",
        "                out = classify(image)\n",
        "\n",
        "                if out == class_idx: correct_count += 1\n",
        "                curr_count += 1\n",
        "            class_idx += 1\n",
        "\n",
        "    print(f\"Total images           : {curr_count}\")\n",
        "    print(f\"Correct predictions    : {correct_count}\")\n",
        "    print(f\"Incorrect predictions  : {curr_count - correct_count}\")\n",
        "    print(f\"Accuracy               : {correct_count / curr_count * 100} %\")\n",
        "\n",
        "# TF Keras\n",
        "classes = list(train_generator.class_indices.keys())\n",
        "test_model('Dataset_Pre', classes, 5153)\n"
      ],
      "metadata": {
        "id": "MX-fd-wNh_Y7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616dc9a7-7caa-46e9-e38f-ff9349892af7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[38;2;255;86;0m 11%\u001b[39m \u001b[38;2;255;86;0m(574 of 5153)\u001b[39m |##                   | Elapsed Time: 0:00:53 ETA:   0:07:03WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
            "\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(5153 of 5153)\u001b[39m |####################| Elapsed Time: 0:08:06 Time:  0:08:06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images           : 5153\n",
            "Correct predictions    : 4141\n",
            "Incorrect predictions  : 1012\n",
            "Accuracy               : 80.3609547836212 %\n"
          ]
        }
      ]
    }
  ]
}